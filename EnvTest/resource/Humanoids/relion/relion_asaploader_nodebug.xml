<AsapVirtualHuman>
  <BMLRealizer>
    <!--LogPipe requestlog="hmi.elckerlyc.requests" /--> <!--only requests -->
    <!--LogPipe requestlog="hmi.elckerlyc.requests" feedbacklog="hmi.elckerlyc.feedback"/--> <!--log both requests and feedback-->
    <!--ServerAdapter requestport="7521" feedbackport="1257"/-->
  </BMLRealizer> 

  <Loader id="guiembodiment" loader="asap.environment.impl.JFrameEmbodiment">
    <BmlUI demoscriptresources="Humanoids/relion/bmlexamples"/>
    <FeedbackUI/>
    <ServerUI/>
    <KillButton/>
  </Loader>

  <Loader id="graphicalembodiment" loader="hmi.relion.RelionEmbodiment">
    <relionconnection server="127.0.0.1" serverport="4446" senderport="4433" avatarname="Relion"/>
  </Loader>

  <!-- since we will be using physics and a mixedanimationengine, we need to transform the skeletonembodiment into a mixedskeletonembodiment -->
  <Loader id="mixedskeletonembodiment" loader="hmi.physicsenvironment.MixedSkeletonEmbodimentLoader" requiredloaders="graphicalembodiment"/>
  
  <!-- load the physicalembodiments and connect them to the mixedskeletonembodiment -->
  <Loader id="physicalembodiment" 
              loader="hmi.physicsenvironment.OdePhysicalEmbodiment"
              requiredloaders="mixedskeletonembodiment">
    <MixedSystems> <!-- preferably, those are generated on the fly from the physical model... but we cannot yet do this :/ -->
      <MixedSystem name="testms"            filename="Humanoids/relion/mixedsystems/relionfull.xml"/> 
    </MixedSystems>
    <GlueFeetToFloor/>
  </Loader>

  <!-- Loader id="physicsdebug" loader="hmi.debug.PhysicsDebugVisualisationLoader" requiredloaders="physicalembodiment">
    <Placement offset="0.5 0 -0.5"/>
  </Loader-->


  <!-- Loader id="skeletondebug" loader="hmi.debug.VJointDebugVisualisationLoader" requiredloaders="graphicalembodiment">
    <Placement offset="-0.5 0 -0.5" type="axis-cross"/>
  </Loader -->

  <Loader id="animationengine" 
          loader="hmi.animationengine.loader.MixedAnimationEngineLoader"
          requiredloaders="mixedskeletonembodiment,physicalembodiment">
    <GestureBinding basedir="" resources="Humanoids/relion/" filename="gesturebinding.xml"/>
    <StartPosition offset="0.2 0 0"/>
    <StartRotation rotation="0 1 0 -0.2"/>
  </Loader>
  

  <Loader id="speechengine" loader="hmi.speechengine.loader.SpeechEngineLoader" requiredloaders="guiembodiment">
    <Voice voicetype="SAPI5" voicename="Kate" factory="WAV_TTS"/> 
    <SpeechUI/>
  </Loader>
  
  <!-- Engine for playing audio files, nice for sound effects (e.g., clapping) or for prerecorded speech fragments -->
  <!--Loader id="audioengine" loader="hmi.audioengine.loader.AudioEngineLoader"/-->

  <!-- Text label embodiment and text speech engine together can be used to put all text on a label (kind of "subcaptions") instead of turning them into audio. If using this, remove the other speechengine -->
  <!--Loader id="textlabel" loader="hmi.textengine.JLabelTextEmbodiment" requiredloaders="guiembodiment"/-->
  <!--Loader id="textspeechengine" loader="hmi.textengine.TextSpeechEngineLoader" requiredloaders="textlabel"/-->
  
</AsapVirtualHuman>
